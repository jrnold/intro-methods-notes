<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>POLS 503: Advanced Quantitative Political Methodology: The Notes</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>">
  <meta name="generator" content="bookdown 0.0.60 and GitBook 2.6.7">

  <meta property="og:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  <meta name="github-repo" content="UW-POLS503/pols503-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="POLS 503: Advanced Quantitative Political Methodology: The Notes" />
  
  <meta name="twitter:description" content="<p>These are notes associated with the course, POLS/CS&amp;SS 503: Advanced Quantitative Political Methodology at the University of Washington.</p>" />
  

<meta name="author" content="Jeffrey B. Arnold">

<meta name="date" content="2016-04-18">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="estimator-properties.html">

<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />











<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>

$$
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

\newcommand{\distr}[1]{\mathcal{#1}}
\newcommand{\dnorm}{\distr{N}}
\newcommand{\dmvnorm}[1]{\distr{N}_{#1}}
$$

  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="ordinary-least-squares-estimator.html"><a href="ordinary-least-squares-estimator.html"><i class="fa fa-check"></i><b>2</b> Ordinary Least Squares Estimator</a><ul>
<li class="chapter" data-level="2.1" data-path="ordinary-least-squares-estimator.html"><a href="ordinary-least-squares-estimator.html#population-linear-regression-function"><i class="fa fa-check"></i><b>2.1</b> Population Linear Regression Function</a></li>
<li class="chapter" data-level="2.2" data-path="ordinary-least-squares-estimator.html"><a href="ordinary-least-squares-estimator.html#sample-linear-regression-function"><i class="fa fa-check"></i><b>2.2</b> Sample Linear Regression Function</a></li>
<li class="chapter" data-level="2.3" data-path="ordinary-least-squares-estimator.html"><a href="ordinary-least-squares-estimator.html#matrix-representation"><i class="fa fa-check"></i><b>2.3</b> Matrix Representation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimator-properties.html"><a href="estimator-properties.html"><i class="fa fa-check"></i><b>3</b> Estimator Properties</a><ul>
<li class="chapter" data-level="3.1" data-path="estimator-properties.html"><a href="estimator-properties.html#assumptions"><i class="fa fa-check"></i><b>3.1</b> Assumptions</a></li>
<li class="chapter" data-level="3.2" data-path="estimator-properties.html"><a href="estimator-properties.html#errors-in-linear-regression"><i class="fa fa-check"></i><b>3.2</b> Errors in Linear Regression</a></li>
<li class="chapter" data-level="3.3" data-path="estimator-properties.html"><a href="estimator-properties.html#non-constant-variance-heteroskedasticity"><i class="fa fa-check"></i><b>3.3</b> Non-constant variance (Heteroskedasticity)</a></li>
<li class="chapter" data-level="3.4" data-path="estimator-properties.html"><a href="estimator-properties.html#why-control-for-variables"><i class="fa fa-check"></i><b>3.4</b> Why Control for Variables</a></li>
<li class="chapter" data-level="3.5" data-path="estimator-properties.html"><a href="estimator-properties.html#multicollinearity"><i class="fa fa-check"></i><b>3.5</b> Multicollinearity</a></li>
<li class="chapter" data-level="3.6" data-path="estimator-properties.html"><a href="estimator-properties.html#most-general-ols-assumptions"><i class="fa fa-check"></i><b>3.6</b> Most general OLS assumptions</a></li>
<li class="chapter" data-level="3.7" data-path="estimator-properties.html"><a href="estimator-properties.html#no-perfect-collinearity"><i class="fa fa-check"></i><b>3.7</b> No perfect collinearity</a></li>
<li class="chapter" data-level="3.8" data-path="estimator-properties.html"><a href="estimator-properties.html#expected-values-of-vectors"><i class="fa fa-check"></i><b>3.8</b> Expected values of vectors</a></li>
<li class="chapter" data-level="3.9" data-path="estimator-properties.html"><a href="estimator-properties.html#ols-is-unbiased"><i class="fa fa-check"></i><b>3.9</b> OLS is unbiased</a></li>
<li class="chapter" data-level="3.10" data-path="estimator-properties.html"><a href="estimator-properties.html#variance-covariance-matrix-of-random-vectors"><i class="fa fa-check"></i><b>3.10</b> Variance-covariance matrix of random vectors</a></li>
<li class="chapter" data-level="3.11" data-path="estimator-properties.html"><a href="estimator-properties.html#matrix-version-of-homoskedasticity"><i class="fa fa-check"></i><b>3.11</b> Matrix version of homoskedasticity</a></li>
<li class="chapter" data-level="3.12" data-path="estimator-properties.html"><a href="estimator-properties.html#sampling-variance-for-ols-estimates"><i class="fa fa-check"></i><b>3.12</b> Sampling variance for OLS estimates</a></li>
<li class="chapter" data-level="3.13" data-path="estimator-properties.html"><a href="estimator-properties.html#inference-in-the-general-setting"><i class="fa fa-check"></i><b>3.13</b> Inference in the general setting</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>4</b> Appendix</a><ul>
<li class="chapter" data-level="4.1" data-path="appendix.html"><a href="appendix.html#covariancevariance-interpretation-of-matrix-ols"><i class="fa fa-check"></i><b>4.1</b> Covariance/variance interpretation of matrix OLS</a></li>
<li class="chapter" data-level="4.2" data-path="appendix.html"><a href="appendix.html#violations-of-the-assumptions"><i class="fa fa-check"></i><b>4.2</b> Violations of the assumptions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ols.html"><a href="ols.html"><i class="fa fa-check"></i><b>5</b> OLS</a></li>
<li class="chapter" data-level="6" data-path="what-makes-an-estimator-good.html"><a href="what-makes-an-estimator-good.html"><i class="fa fa-check"></i><b>6</b> What makes an estimator good?</a><ul>
<li class="chapter" data-level="6.1" data-path="what-makes-an-estimator-good.html"><a href="what-makes-an-estimator-good.html#assumptions-1"><i class="fa fa-check"></i><b>6.1</b> Assumptions</a></li>
<li class="chapter" data-level="6.2" data-path="what-makes-an-estimator-good.html"><a href="what-makes-an-estimator-good.html#references"><i class="fa fa-check"></i><b>6.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix-1.html"><a href="appendix-1.html"><i class="fa fa-check"></i><b>7</b> Appendix</a><ul>
<li class="chapter" data-level="7.1" data-path="appendix-1.html"><a href="appendix-1.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>7.1</b> Multivariate Normal Distribution</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">POLS 503: Advanced Quantitative Political Methodology: The Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ordinary-least-squares-estimator" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Ordinary Least Squares Estimator</h1>
<p>Since we will largely be concerned with using linear regression for inference, we will start by discussion the population parameter of interest (population linear regression function), then the sample statistic (sample linear regression function) and estimator (ordinary least squares).</p>
<p>We will then consider the properties of the OLS estimator.</p>
<div id="population-linear-regression-function" class="section level2">
<h2><span class="header-section-number">2.1</span> Population Linear Regression Function</h2>
<p>The population linear regression function is <span class="math display">\[
r(x) = \E[Y | X = x] = \beta_0 + \sum_{k = 1}^{K} \beta_{k} x_k .
\]</span></p>
</div>
<div id="sample-linear-regression-function" class="section level2">
<h2><span class="header-section-number">2.2</span> Sample Linear Regression Function</h2>
<p>The sample linear regression function is <span class="math display">\[
\hat{r}(x_i) = \hat{y}_i = \hat\beta_0 + \sum_{k = 1}^{K} \hat\beta_{k} x_k .
\]</span></p>
<ul>
<li><span class="math inline">\(\hat{Y}_i\)</span> are the fitted or predicted value</li>
<li>The <strong>residuals</strong> or <strong>errors</strong> are the prediction errors of the estimates <span class="math display">\[
\hat{\epsilon}_i = y_i - \hat{y}_i
\]</span></li>
</ul>
</div>
<div id="matrix-representation" class="section level2">
<h2><span class="header-section-number">2.3</span> Matrix Representation</h2>
<p>The linear regression function can be written as a scalar function for each observation, <span class="math inline">\(i = 1, \dots, N\)</span>, <span class="math display">\[
\begin{aligned}[t]
y_i &amp;= \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_{K,i} + \varepsilon_i \\
 &amp;= \beta_0 + \sum_{k = 1}^{K} \beta_k x_{k,i} + \varepsilon_i \\
&amp;= \sum_{k = 0}^{K} \beta_k x_{k,i} + \varepsilon_i
\end{aligned}
\]</span> where <span class="math inline">\(x_{0,i} = 1\)</span> for all <span class="math inline">\(i \in 1:N\)</span>.</p>
<p>The linear regression can be more compactly written in matrix form, <span class="math display">\[
\begin{aligned}[t]
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_N
\end{bmatrix} &amp;=
\begin{bmatrix} 
1 &amp; x_{1,1} &amp; x_{2,1} &amp; \cdots &amp; x_{K,1} \\
1 &amp; x_{1,2} &amp; x_{2,2} &amp; \cdots &amp; x_{K,2} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{1,N}&amp; x_{2,n} &amp; \cdots &amp; x_{K,N}
\end{bmatrix}
\begin{bmatrix} 
\beta_0 \\
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_K
\end{bmatrix}
+ 
\begin{bmatrix}
\varepsilon_1 \\
\varepsilon_2 \\
\vdots \\
\varepsilon_N
\end{bmatrix}
\\
\underbrace{\vec{y}}_{N \times 1} &amp;= \underbrace{\mat{X}}_{N \times K} \,\, \underbrace{\vec{\beta}}_{K \times 1} + \underbrace{\vec{\varepsilon}}_{N \times 1}
\end{aligned}
\]</span> The matrix <span class="math inline">\(\mat{X}\)</span> is called the <em>design</em> matrix. Its rows are each observation in the data. Its columns are the intercept, a column vector of 1â€™s, and the values of each predictor.</p>
<p>The mean of the disturbance vector is 0, <span class="math display">\[
\E(\epsilon) = 0
\]</span></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimator-properties.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/UW-POLS503/pols503-notes/edit/gh-pages/ols-estimator.Rmd",
"text": "Edit"
},
"download": ["pols503-notes.pdf", "pols503-notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>


</body>

</html>
